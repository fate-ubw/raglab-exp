num_gpu: 2
output_dir: /home/zxw/rag/raglab-exp/1-eval_output
# llm config
llm_path: /home/zxw/rag/model/Llama-2-7b-hf
generate_maxlength: 300
use_vllm:
# retrieval common config
retrieval_name: contriever
index_dbPath: /home/zxw/rag/data/2-wikipidia_embedding_debug/*
text_dbPath: /home/zxw/rag/data/2-self_rag-retrieval_passages/psgs_w100.tsv
eval_datapath: /home/zxw/rag/data/1-self_rag/2-eval_data/popqa_longtail_w_gs.jsonl
retriever_modelPath: /home/zxw/rag/model/contriever-msmarco
n_docs: 5
# colbert config
nbits: 2
# contriever config
projection_size: 768
indexing_batch_size: 1000000 
n_bits: 8
n_subquantizers: 0
per_gpu_batch_size: 64 #Batch size for question encoding 为什么 question 的时候是 64 维度，可能得看一下论文
question_maxlength: 512 # Maximum number of tokens in a question

