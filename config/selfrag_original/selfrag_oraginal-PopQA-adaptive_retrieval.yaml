use_seed: True
seed: 633
# GPU config
num_gpu: 2
# eval config
eval_datapath: ./data/eval_datasets/popqa_longtail_w_gs.jsonl
task: PopQA
output_dir: ./1-eval_output/
# llm config
llm_path: ./model/selfrag_llama2_7b/
dtype: "half"
generate_maxlength: 100
use_vllm: True
temperature: 0.0
top_p: 1.0
generation_stop: ''
# retrieval common config
n_docs: 10
# self rag 
download_dir: ".cache"
world_size: 1
threshold: 0.2  
use_seqscore: True
use_groundness: True
use_utility: True
beam_width: 2
max_depth: 7
w_rel: 1.0
w_sup: 1.0
w_use: 0.5
retrieval_mode: "adaptive_retrieval"
show_specialtokens: True
inference_form: 'short_form'
ignore_cont: False

